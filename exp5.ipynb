{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tiny_tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-0.5B\")\n",
    "tiny_model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-0.5B\")\n",
    "# Load the dataset\n",
    "dataset = load_dataset('wikitext', 'wikitext-2-raw-v1', split='train')\n",
    "reference_tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-7B-Instruct\")\n",
    "reference_model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-7B-Instruct\")\n",
    "# Load the reference and tiny LLaMA models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Calculate reference loss for each token in the dataset\n",
    "def calculate_reference_loss(dataset):\n",
    "    reference_loss_dict = {}\n",
    "    for example in dataset:\n",
    "        text = example['text']\n",
    "        inputs = reference_tokenizer(text, return_tensors='pt')\n",
    "        with torch.no_grad():\n",
    "            outputs = reference_model(**inputs, labels=inputs['input_ids'])\n",
    "            loss = outputs.loss.item()\n",
    "            for token_id in inputs['input_ids'][0]:\n",
    "                reference_loss_dict[token_id.item()] = -loss  # Store negative log likelihood\n",
    "    return reference_loss_dict\n",
    "\n",
    "reference_loss_dict = calculate_reference_loss(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function for tiny LLaMA\n",
    "def train_tiny_llama(tiny_model, dataset, reference_loss_dict):\n",
    "    optimizer = torch.optim.Adam(tiny_model.parameters(), lr=1e-4)\n",
    "    num_epochs = 3\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for example in dataset:\n",
    "            text = example['text']\n",
    "            inputs = tiny_tokenizer(text, return_tensors='pt')\n",
    "            outputs = tiny_model(**inputs, labels=inputs['input_ids'])\n",
    "            loss = outputs.loss\n",
    "\n",
    "            # Calculate excess loss\n",
    "            excess_losses = []\n",
    "            for token_id, token_loss in zip(inputs['input_ids'][0], loss):\n",
    "                reference_loss = reference_loss_dict.get(token_id.item(), 0)\n",
    "                excess_loss = token_loss.item() - reference_loss\n",
    "                excess_losses.append(excess_loss)\n",
    "\n",
    "            # Find top 30% excess losses\n",
    "            threshold = np.percentile(excess_losses, 70)\n",
    "            modified_losses = [loss if excess_loss >= threshold else 0 for loss, excess_loss in zip(loss, excess_losses)]\n",
    "\n",
    "            # Backpropagation with modified losses\n",
    "            modified_loss = torch.tensor(modified_losses, requires_grad=True).mean()\n",
    "            optimizer.zero_grad()\n",
    "            modified_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "train_tiny_llama(tiny_model, dataset, reference_loss_dict)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
